# Cartridge2 Docker Compose Configuration
#
# Services:
#   - alphazero:  Synchronized AlphaZero training (RECOMMENDED)
#   - evaluator:  Periodic model evaluation against random baseline
#   - actor:      Standalone self-play (for continuous training)
#   - trainer:    Standalone training (for continuous training)
#   - web:        Backend API server
#   - frontend:   Nginx serving Svelte frontend
#
# Shared volume: ./data (SQLite DB, ONNX models, stats.json)
#
# Quick Start:
#   # Train a model (with evaluation after each iteration)
#   docker compose up alphazero
#
#   # Train Connect4 instead of TicTacToe
#   ALPHAZERO_ENV_ID=connect4 docker compose up alphazero
#
#   # Play against the trained model
#   docker compose up web frontend
#   # Open http://localhost in browser
#
#   # Run standalone evaluation
#   docker compose run --rm evaluator
#
#   # Watch training progress
#   docker compose logs -f alphazero

services:
  # ==========================================================================
  # AlphaZero - Synchronized Training (RECOMMENDED)
  # ==========================================================================
  # Each iteration: clear buffer -> generate episodes -> train -> evaluate
  # This ensures training data comes from the current model only
  alphazero:
    build:
      context: .
      dockerfile: Dockerfile.alphazero
    container_name: cartridge-alphazero
    volumes:
      - ./data:/app/data
    environment:
      # Game environment
      - ALPHAZERO_ENV_ID=${ALPHAZERO_ENV_ID:-tictactoe}

      # Training loop settings
      - ALPHAZERO_ITERATIONS=${ALPHAZERO_ITERATIONS:-100}
      - ALPHAZERO_EPISODES=${ALPHAZERO_EPISODES:-500}
      - ALPHAZERO_STEPS=${ALPHAZERO_STEPS:-1000}
      - ALPHAZERO_START_ITERATION=${ALPHAZERO_START_ITERATION:-1}

      # Training hyperparameters
      - ALPHAZERO_BATCH_SIZE=${ALPHAZERO_BATCH_SIZE:-64}
      - ALPHAZERO_LR=${ALPHAZERO_LR:-0.001}
      - ALPHAZERO_DEVICE=${ALPHAZERO_DEVICE:-cpu}
      - ALPHAZERO_CHECKPOINT_INTERVAL=${ALPHAZERO_CHECKPOINT_INTERVAL:-100}

      # Evaluation settings (enabled by default!)
      - ALPHAZERO_EVAL_INTERVAL=${ALPHAZERO_EVAL_INTERVAL:-1}
      - ALPHAZERO_EVAL_GAMES=${ALPHAZERO_EVAL_GAMES:-50}
    networks:
      - cartridge-net

  # ==========================================================================
  # Evaluator - Standalone Model Evaluation
  # ==========================================================================
  # Evaluates the latest model against random baseline
  # Can be run as a one-shot or on a schedule
  evaluator:
    build:
      context: trainer
      dockerfile: Dockerfile
    container_name: cartridge-evaluator
    profiles:
      - tools
    volumes:
      - ./data:/app/data
    environment:
      - DATA_DIR=/app/data
    entrypoint: ["python", "-m", "trainer", "evaluate"]
    command:
      - "--model=/app/data/models/latest.onnx"
      - "--db=/app/data/replay.db"
      - "--env-id=${ALPHAZERO_ENV_ID:-tictactoe}"
      - "--games=${EVAL_GAMES:-100}"
    networks:
      - cartridge-net

  # ==========================================================================
  # Actor - Standalone Self-Play (continuous mode)
  # ==========================================================================
  # Generates self-play episodes independently
  # Use for continuous/async training setups
  actor:
    build:
      context: .
      dockerfile: actor/Dockerfile
    container_name: cartridge-actor
    profiles:
      - continuous
    restart: unless-stopped
    volumes:
      - ./data:/app/data
    environment:
      - ACTOR_ACTOR_ID=actor-1
      - ACTOR_ENV_ID=${ALPHAZERO_ENV_ID:-tictactoe}
      - ACTOR_MAX_EPISODES=-1
      - ACTOR_LOG_LEVEL=info
      - ACTOR_REPLAY_DB_PATH=/app/data/replay.db
      - ACTOR_DATA_DIR=/app/data
    networks:
      - cartridge-net

  # ==========================================================================
  # Trainer - Standalone Training (continuous mode)
  # ==========================================================================
  # Trains on replay buffer data independently
  # Use for continuous/async training setups
  trainer:
    build:
      context: trainer
      dockerfile: Dockerfile
    container_name: cartridge-trainer
    profiles:
      - continuous
    restart: unless-stopped
    volumes:
      - ./data:/app/data
    environment:
      - DATA_DIR=/app/data
    entrypoint: ["python", "-m", "trainer", "train"]
    command:
      - "--db=/app/data/replay.db"
      - "--model-dir=/app/data/models"
      - "--stats=/app/data/stats.json"
      - "--env-id=${ALPHAZERO_ENV_ID:-tictactoe}"
      - "--device=${TRAINER_DEVICE:-cpu}"
      - "--steps=${TRAINER_STEPS:-1000}"
      - "--batch-size=${TRAINER_BATCH_SIZE:-64}"
      - "--lr=${TRAINER_LR:-0.001}"
    networks:
      - cartridge-net

  # ==========================================================================
  # Web Backend - API server with game logic
  # ==========================================================================
  web:
    build:
      context: .
      dockerfile: web/Dockerfile
    container_name: cartridge-web
    restart: unless-stopped
    volumes:
      - ./data:/app/data
    environment:
      - DATA_DIR=/app/data
      - DEFAULT_GAME=${ALPHAZERO_ENV_ID:-tictactoe}
      - RUST_LOG=info
    ports:
      - "8080:8080"
    networks:
      - cartridge-net

  # ==========================================================================
  # Frontend - Nginx serving Svelte app + proxying API
  # ==========================================================================
  frontend:
    build:
      context: web/frontend
      dockerfile: Dockerfile
    container_name: cartridge-frontend
    restart: unless-stopped
    ports:
      - "80:80"
    depends_on:
      - web
    networks:
      - cartridge-net

networks:
  cartridge-net:
    driver: bridge

volumes:
  data:
    driver: local
