# AlphaZero Synchronized Training Container
#
# Bundles both the Rust actor and Python trainer for synchronized training.
# Each iteration: clear buffer -> run actor -> train -> evaluate -> repeat
#
# Usage:
#   docker build -f Dockerfile.alphazero -t cartridge-alphazero .
#   docker run -v ./data:/app/data cartridge-alphazero
#
# Or via docker-compose:
#   docker compose up alphazero

# ============================================
# Stage 1: Build Rust Actor
# ============================================
FROM rust:1.85-bookworm AS rust-builder

RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy and build actor
COPY engine/ ./engine/
COPY actor/ ./actor/

WORKDIR /app/actor
RUN cargo build --release

# ============================================
# Stage 2: Python Runtime with Actor Binary
# ============================================
FROM python:3.11-slim-bookworm

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy actor binary from rust builder
COPY --from=rust-builder /app/actor/target/release/actor /app/actor

# Copy trainer source and install
COPY trainer/pyproject.toml trainer/README.md ./trainer/
COPY trainer/src/ ./trainer/src/

# Install CPU-only PyTorch (avoids ~700MB CUDA download)
RUN pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cpu

# Install trainer package
RUN pip install --no-cache-dir ./trainer

# Create data directory
RUN mkdir -p /app/data/models

# ============================================
# Environment Configuration
# ============================================
# Actor binary location (used by orchestrator)
ENV ACTOR_BINARY="/app/actor"

# Data paths
ENV DATA_DIR="/app/data"

# AlphaZero training defaults
ENV ALPHAZERO_ENV_ID="tictactoe"
ENV ALPHAZERO_ITERATIONS="100"
ENV ALPHAZERO_EPISODES="500"
ENV ALPHAZERO_STEPS="1000"
ENV ALPHAZERO_BATCH_SIZE="64"
ENV ALPHAZERO_LR="0.001"
ENV ALPHAZERO_DEVICE="cpu"

# Evaluation enabled by default (every iteration)
ENV ALPHAZERO_EVAL_INTERVAL="1"
ENV ALPHAZERO_EVAL_GAMES="50"

ENV ALPHAZERO_CHECKPOINT_INTERVAL="100"
ENV ALPHAZERO_START_ITERATION="1"

# Run the synchronized training loop
ENTRYPOINT ["python", "-m", "trainer", "loop"]
