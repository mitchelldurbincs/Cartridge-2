# Trainer Deployment - Neural network training
#
# Single replica deployment that:
# 1. Reads transitions from PostgreSQL replay buffer
# 2. Trains the neural network
# 3. Exports ONNX checkpoints to shared volume
#
# This is NOT horizontally scalable (training is sequential).
# The trainer runs in a continuous loop, training on available data.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: trainer
  namespace: cartridge
  labels:
    app.kubernetes.io/name: trainer
    app.kubernetes.io/component: training
    app.kubernetes.io/part-of: cartridge2
spec:
  # Training is sequential - only one replica
  replicas: 1
  strategy:
    type: Recreate  # Don't overlap trainers
  selector:
    matchLabels:
      app.kubernetes.io/name: trainer
  template:
    metadata:
      labels:
        app.kubernetes.io/name: trainer
        app.kubernetes.io/component: training
        app.kubernetes.io/part-of: cartridge2
    spec:
      initContainers:
        # Wait for PostgreSQL to be ready
        - name: wait-for-postgres
          image: busybox:1.36
          command:
            - sh
            - -c
            - |
              echo "Waiting for PostgreSQL..."
              until nc -z postgres 5432; do
                echo "PostgreSQL not ready, waiting..."
                sleep 2
              done
              echo "PostgreSQL is ready!"
      containers:
        - name: trainer
          # Same image as actor (includes both binaries)
          image: cartridge-alphazero:latest
          imagePullPolicy: IfNotPresent
          # Run the trainer in continuous mode
          # Note: Using 'train' not 'loop' because loop spawns actors internally
          command: ["python", "-m", "trainer", "train"]
          args:
            - "--env-id=$(ENV_ID)"
            - "--model-dir=/data/models"
            - "--stats-path=/data/stats.json"
            - "--steps=0"  # 0 = infinite loop
            - "--batch-size=$(BATCH_SIZE)"
            - "--lr=$(LEARNING_RATE)"
            - "--device=$(DEVICE)"
            - "--checkpoint-interval=100"
            - "--max-wait=0"  # Wait forever for data
          env:
            - name: ENV_ID
              valueFrom:
                configMapKeyRef:
                  name: cartridge-config
                  key: ENV_ID
            - name: BATCH_SIZE
              valueFrom:
                configMapKeyRef:
                  name: cartridge-config
                  key: BATCH_SIZE
            - name: LEARNING_RATE
              valueFrom:
                configMapKeyRef:
                  name: cartridge-config
                  key: LEARNING_RATE
            - name: DEVICE
              valueFrom:
                configMapKeyRef:
                  name: cartridge-config
                  key: DEVICE
            - name: CARTRIDGE_STORAGE_POSTGRES_URL
              valueFrom:
                secretKeyRef:
                  name: postgres-credentials
                  key: POSTGRES_URL
            # S3 credentials for future model upload support
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: AWS_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: AWS_SECRET_ACCESS_KEY
            - name: CARTRIDGE_STORAGE_S3_ENDPOINT
              valueFrom:
                configMapKeyRef:
                  name: cartridge-config
                  key: S3_ENDPOINT
            - name: CARTRIDGE_STORAGE_S3_BUCKET
              valueFrom:
                configMapKeyRef:
                  name: cartridge-config
                  key: S3_BUCKET
          volumeMounts:
            - name: models
              mountPath: /data/models
            - name: data
              mountPath: /data
          resources:
            requests:
              memory: "1Gi"
              cpu: "1000m"
            limits:
              memory: "4Gi"
              cpu: "2000m"
              # Uncomment for GPU training:
              # nvidia.com/gpu: 1
      volumes:
        - name: models
          persistentVolumeClaim:
            claimName: models-shared
        - name: data
          emptyDir: {}
      # Prefer nodes with more memory for training
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              preference:
                matchExpressions:
                  - key: node.kubernetes.io/instance-type
                    operator: In
                    values:
                      - m5.xlarge
                      - m5.2xlarge
                      - c5.xlarge
                      - c5.2xlarge
